{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_network():\n",
    "    def __init__(self,sess,n_parts, input_dim, output_dim, n_hidden =400,rate = 0.3, mu = 0, sigma = 1):\n",
    "        self.n_parts = n_parts\n",
    "        self.n_hidden = n_hidden\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rate = rate\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        self.phi = tf.placeholder(tf.float32,shape=(n_parts,self.output_dim))\n",
    "        self.model = self.build_network()\n",
    "        self.eta_grad = tf.gradients(tf.multiply(tf.stop_gradient(self.phi), self.model.output),self.model.trainable_weights)\n",
    "    \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def build_network(self):\n",
    "        encoder_inputs = Input(batch_shape=(self.n_parts,self.input_dim,))\n",
    "        #encoder_inputs = Dropout(self.rate,input_shape=(None, self.input_dim))\n",
    "        encoder_hidden = Dense(self.n_hidden, activation='tanh',\n",
    "                       kernel_initializer = RandomNormal(self.mu,self.sigma),\n",
    "                               bias_initializer = RandomNormal(self.mu,self.sigma))(encoder_inputs)\n",
    "        encoder_hidden = Dropout(self.rate)(encoder_hidden)\n",
    "        encoder_output = Dense(self.output_dim,\n",
    "                       kernel_initializer = RandomNormal(self.mu,self.sigma),\n",
    "                               bias_initializer = RandomNormal(self.mu,self.sigma))(encoder_hidden)\n",
    "        encoder = Model(inputs = encoder_inputs, outputs = encoder_output)\n",
    "        \n",
    "        return encoder\n",
    "            \n",
    "    def eval_eta_grad(self,x_in,phi):\n",
    "        return self.sess.run(self.eta_grad, feed_dict={self.model.input : x_in,self.phi : phi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_network():\n",
    "    def __init__(self,sess,n_parts,input_dim,output_dim,n_hidden = 400,rate = 0.3, mu = 0, sigma = 1):\n",
    "        self.n_parts = n_parts\n",
    "        self.n_hidden = n_hidden\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rate = rate\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.sess = sess\n",
    "        \n",
    "        self.model = self.build_network()\n",
    "        \n",
    "        self.x_real = tf.placeholder(tf.float32, shape=(self.output_dim,))\n",
    "        \n",
    "        self.logpxz= tf.placeholder(tf.float32,shape=(self.output_dim,))\n",
    "#        self.logpxz = self.eval_logpxz(self.x_real, self.model.output)\n",
    "        \n",
    "        self.theta_grad = tf.gradients(self.logpxz, self.model.trainable_weights)\n",
    "        self.z_grad = tf.gradients(self.logpxz, self.model.input)\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def build_network(self):\n",
    "        decoder_inputs = Input(batch_shape=(None, self.input_dim))\n",
    "        #decoder_inputs = Dropout(self.rate,input_shape=(None, self.input_dim))\n",
    "        decoder_hidden = Dense(self.n_hidden,activation='tanh',\n",
    "                               kernel_initializer = RandomNormal(self.mu,self.sigma),\n",
    "                               bias_initializer = RandomNormal(self.mu,self.sigma))(decoder_inputs)\n",
    "        decoder_hidden = Dropout(self.rate)(decoder_hidden)\n",
    "        decoder_output = Dense(self.output_dim, activation='sigmoid',\n",
    "                               kernel_initializer = RandomNormal(self.mu,self.sigma),\n",
    "                               bias_initializer = RandomNormal(self.mu,self.sigma))(decoder_hidden)\n",
    "        decoder = Model(inputs = decoder_inputs, outputs = decoder_output)\n",
    "        return decoder        \n",
    "    \n",
    "    # grad with respect to theta of log p(x|z)\n",
    "    def eval_theta_grad(self,z,x_in):\n",
    "        return self.sess.run(self.theta_grad,feed_dict={self.model.input:z, self.x_real:x_in})\n",
    "    def debug_theta_grad(self,logpxz):\n",
    "        return self.sess.run(self.theta_grad,feed_dict={self.logpxz:logpxz})\n",
    "    # grad with respect to z of log p(x|z)\n",
    "    def eval_z_grad(self,z,x_in):\n",
    "        return self.sess.run(self.z_grad,feed_dict={self.model.input:z, self.x_real:x_in})\n",
    "    \n",
    "    def debug_z_grad(self,logpxz,z):\n",
    "        return self.sess.run(self.z_grad,feed_dict ={self.logpxz:logpxz,self.model.input :z})\n",
    "    \n",
    "    def eval_logpxz(self, x_real, x_rec):\n",
    "        x_real = tf.reshape(x_real,(1,self.output_dim))\n",
    "        X_real = tf.tile(x_real,(self.n_parts,1))\n",
    "        x_rec  = tf.reshape(x_rec,(self.n_parts,self.output_dim))\n",
    "        \n",
    "        fudge = 1e-15\n",
    "        \n",
    "        part1 = X_real * tf.log(x_rec + fudge)\n",
    "        part2 = (1-X_real) * tf.log(1-x_rec + fudge)\n",
    "        \n",
    "        logpxz = tf.reduce_sum(tf.where(X_real==1, part1, part2), axis=1)\n",
    "        \n",
    "        return logpxz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(x,h = -1):\n",
    "        dist_mat = distance.squareform(distance.pdist(x)) **2 #use scipy package to calculate pairwise euclidean distance mat\n",
    "\n",
    "        if h < 0 : #as suggested in the paper, calculate bandwith like so\n",
    "            h = np.sqrt(0.5*np.median(dist_mat) / np.log(x.shape[0]+1))\n",
    "\n",
    "        kxy = np.exp(-dist_mat / h**2 /2) #rbf kernel formula\n",
    "\n",
    "        dkxy = -np.matmul(kxy , x) #first part of derivative of kxy\n",
    "        for i in range(x.shape[1]): #second part of derivative of kxy\n",
    "            dkxy[:,i] += x[:,i] * np.sum(kxy,axis=1)\n",
    "        dkxy /= h**2\n",
    "        return kxy, dkxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_input(x_input, loc, scale, n_parts):\n",
    "    \n",
    "    xsi = np.random.normal(loc,scale,size=(n_parts,1))\n",
    "    x_extended = np.tile(x_input,(n_parts,1))\n",
    "    \n",
    "    assert np.shape(x_extended) == (n_parts, np.size(x_input))\n",
    "\n",
    "    return np.hstack((x_extended,xsi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_f, y_train_f), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "iters = 1000\n",
    "n_parts = 5\n",
    "latent_dim = 2\n",
    "n_hidden = 400\n",
    "\n",
    "loc = 0\n",
    "scale = 1\n",
    "epsilon = 1e-4\n",
    "\n",
    "num_samples = x_train_f.shape[0]\n",
    "num_val = 10000\n",
    "num_train = num_samples - num_val\n",
    "\n",
    "orig_dim = x_train_f.shape[1:] #useful for restoring original images\n",
    "flat_dim = orig_dim[0] * orig_dim[1] #output dimension\n",
    "input_dim = flat_dim +1 #input dimension\n",
    "\n",
    "shuffle_idx = np.random.permutation(num_samples)\n",
    "x_val = np.round(x_train_f[shuffle_idx[:num_val]].copy().reshape(-1,flat_dim) / 255)\n",
    "y_val = y_train_f[shuffle_idx[:num_val]].copy()\n",
    "x_train = np.round(x_train_f[shuffle_idx[num_val:]].copy().reshape(-1,flat_dim) / 255)\n",
    "y_train = y_train_f[shuffle_idx[num_val:]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "encoder = encoder_network(sess, n_parts, input_dim, latent_dim)\n",
    "decoder = decoder_network(sess, n_parts, latent_dim, flat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"Sum:0\", shape=(5,), dtype=float32) which was passed to the feed with key Tensor(\"Placeholder_2:0\", shape=(784,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-5e3730960525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_parts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlogpxz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_logpxz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mz_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_z_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogpxz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtheta_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_theta_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogpxz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-257-8d5e45a8a3f5>\u001b[0m in \u001b[0;36mdebug_z_grad\u001b[1;34m(self, logpxz, z)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_z_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogpxz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogpxz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlogpxz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_logpxz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1089\u001b[0m                             \u001b[1;34m'For reference, the tensor object was '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' which was passed to the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m                             'feed with key ' + str(feed) + '.')\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m           \u001b[0msubfeed_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"Sum:0\", shape=(5,), dtype=float32) which was passed to the feed with key Tensor(\"Placeholder_2:0\", shape=(784,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "for t in range(iters):\n",
    "    x_input = extend_input(x_train[t],loc, scale, n_parts)\n",
    "\n",
    "    z = encoder.model.predict(x_input,batch_size=n_parts)\n",
    "    \n",
    "    x_rec = decoder.model.predict(z,batch_size=n_parts)\n",
    "    logpxz = decoder.eval_logpxz(tf.cast(x_train[t],dtype=tf.float32),x_rec)\n",
    "    z_grad = decoder.debug_z_grad(logpxz,z)\n",
    "    theta_grad = decoder.debug_theta_grad(logpxz)\n",
    "    \n",
    "#     z_grad = decoder.eval_z_grad(z,x_train[t])\n",
    "    z_grad = np.array(z_grad).reshape(n_parts,latent_dim)\n",
    "        \n",
    "    kzy, dkzy = rbf_kernel(z)\n",
    "    phi = (kzy @ (z_grad - z) + dkzy) / n_parts\n",
    "    \n",
    "    \n",
    "    eta_grad = encoder.eval_eta_grad(x_input,phi)\n",
    "    \n",
    "    eta_1 = []\n",
    "    for i,eta in enumerate(encoder.model.get_weights()):\n",
    "        eta_1.append(eta + epsilon * eta_grad[i])\n",
    "    \n",
    "    \n",
    "#     theta_grad = decoder.eval_theta_grad(z,x_train[t])\n",
    "    theta_1 = []\n",
    "    for i,theta in enumerate(decoder.model.get_weights()):\n",
    "        theta_1.append(theta + theta_grad[i] / n_parts)\n",
    "    decoder.model.set_weights(theta_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extend_input(x_val[0],loc, scale, n_parts)\n",
    "z = encoder.model.predict(test,batch_size=n_parts)\n",
    "prediction = decoder.model.predict(z)\n",
    "prediction = np.mean(prediction,axis=0)\n",
    "x_rec = np.round(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))\n",
    "plt.show()\n",
    "plt.imshow(prediction.reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/BiasAdd:0' shape=(50, 32) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     def build_grad(self):\n",
    "#         grads = []\n",
    "#         for eta in self.model.trainable_weights:\n",
    "#             a = []\n",
    "#             for i in range(self.n_parts):\n",
    "#                 b = []\n",
    "#                 for j in range(self.output_dim):\n",
    "#                     b.append(tf.gradients(self.model.output[i,j],eta))\n",
    "#                 a.append(b)\n",
    "#             grads.append(a)\n",
    "#         return grads\n",
    "\n",
    "#     eta_1 = []\n",
    "#     for i,eta in enumerate(encoder.model.get_weights()):\n",
    "#         a = np.array(eta_grad[i]).reshape(n_parts,latent_dim,-1)\n",
    "#         b = np.array([np.matmul(phi[j,:].reshape(1,latent_dim),a[j,:,:]) for j in range(n_parts)])\n",
    "        \n",
    "#         eta_1.append(eta + epsilon * np.sum(b,axis=0).reshape(eta.shape))\n",
    "#     encoder.model.set_weights(eta_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
