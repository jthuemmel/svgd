{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import elu, dropout, log_softmax, nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_binarization(img):\n",
    "    return t.distributions.bernoulli.Bernoulli(img).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(x_real, x_rec):\n",
    "    return t.sum(x_real * t.log(x_rec+1e-15) + (1 - x_real) * t.log(1 - x_rec + 1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svgd_kernel(x):\n",
    "    n = t.Tensor([x.size(0)])\n",
    "    assert n > 1\n",
    "    \n",
    "    norm = (x ** 2).sum(1).view(-1, 1)\n",
    "    dist_mat = (norm + norm.view(1, -1)) - 2.0 * t.mm(x , x.t())\n",
    "    \n",
    "    h = t.median(dist_mat) / t.log(n)\n",
    "    \n",
    "    kxy = t.exp(- dist_mat / h)\n",
    "    dxkxy = (-t.mm(kxy,x) + t.sum(kxy,1).view(-1,1)*x) / (2*h) \n",
    "    \n",
    "    return kxy, dxkxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/T480/AnacondaProjects/svgd/'\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1000\n",
    "n_epochs = 5\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tv.datasets.MNIST(path,train = True,download = True, \n",
    "                               transform = tv.transforms.Compose(\n",
    "                                   [tv.transforms.ToTensor(),tv.transforms.Lambda(dynamic_binarization)]))\n",
    "test_data = tv.datasets.MNIST(path,train = False, download = True, transform = tv.transforms.Compose(\n",
    "                                   [tv.transforms.ToTensor(),tv.transforms.Lambda(dynamic_binarization)]))\n",
    "train_loader = t.utils.data.DataLoader(train_data,batch_size = batch_size_train, shuffle = True)\n",
    "test_loader = t.utils.data.DataLoader(test_data,batch_size = batch_size_test, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.drop_rate = 0.3\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,16,kernel_size = 5,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size = 5,stride = 2)\n",
    "        self.dense = nn.Linear(512,512)\n",
    "        self.out = nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = elu(self.conv1(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = elu(self.conv2(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = x.view(-1,512)\n",
    "        x = elu(self.dense(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = log_softmax(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_encoder(nn.Module):\n",
    "    def __init__(self,n_hidden,input_dim, output_dim, drop_rate):\n",
    "        super(cnn_encoder,self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,16,kernel_size = 5,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size = 5,stride = 2)\n",
    "        self.out = nn.Linear(n_hidden,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = elu(self.conv1(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = elu(self.conv2(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = x.view(-1,512)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "class cnn_decoder(nn.Module):\n",
    "    def __init__(self,n_hidden,input_dim, output_dim, drop_rate):\n",
    "        super(cnn_decoder,self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "        self.input = nn.Linear(input_dim, n_hidden)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32,16,kernel_size = 5, stride = 2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16,1,kernel_size = 5, stride = 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input(x)\n",
    "        x = dropout(x, self.drop_rate)\n",
    "        x = x.view(-1,32,4,4)\n",
    "        x = elu(self.deconv1(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = elu(self.deconv2(x))\n",
    "        x = t.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = cnn_encoder(512,784,32,0)\n",
    "decoder = cnn_decoder(512,32,784,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_encoder(nn.Module):\n",
    "    def __init__(self,n_hidden,input_dim, output_dim, drop_rate):\n",
    "        super(mlp_encoder,self).__init__()\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        self.hidden = nn.Linear(input_dim,n_hidden)\n",
    "        self.out = nn.Linear(n_hidden,output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = elu(self.hidden(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "class mlp_decoder(nn.Module):\n",
    "    def __init__(self,n_hidden,input_dim, output_dim, drop_rate):\n",
    "        super(mlp_decoder,self).__init__()\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        self.hidden = nn.Linear(input_dim,n_hidden)\n",
    "        self.out = nn.Linear(n_hidden, output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = elu(self.hidden(x))\n",
    "        x = dropout(x,self.drop_rate)\n",
    "        x = t.sigmoid(self.out(x))\n",
    "        return x\n",
    "    \n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, n_hidden, input_dim, output_dim, drop_rate):\n",
    "        super(classifier,self).__init__()\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        self.hidden = nn.Linear(input_dim, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden, output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = elu(self.hidden(x))\n",
    "        x = dropout(x, self.drop_rate)\n",
    "        x = log_softmax(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svgd():\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for batch_index, (data,target) in enumerate(train_loader):\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        \n",
    "        img = data.repeat(n_parts,1,1,1).view(n_parts, 1, 28, 28)\n",
    "        x = dropout(img, input_drop_rate)\n",
    "        z = encoder(x).squeeze()\n",
    "        \n",
    "        z_for_grad = z.detach()\n",
    "        z_for_grad.requires_grad = True\n",
    "        x_rec = decoder(z_for_grad)\n",
    "\n",
    "        logpxz = (-1/n_parts) * bce_loss(img,x_rec)\n",
    "        logpxz.backward()\n",
    "        \n",
    "        with t.no_grad():\n",
    "            kzy, dzkzy = svgd_kernel(z)\n",
    "            phi = (t.mm(kzy,(-n_parts)*z_for_grad.grad - z) + (1. + alpha) * dzkzy)/n_parts\n",
    "            \n",
    "        eta_grad = t.autograd.grad(-(phi * z).sum(), encoder.parameters())\n",
    "        \n",
    "        enc_opt.step()\n",
    "        dec_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_drop_rate = 0.3\n",
    "alpha = 0\n",
    "n_parts = 5\n",
    "\n",
    "n_hidden = 512\n",
    "latent_dim = 32\n",
    "data_dim = 784\n",
    "model_drop_rate = 0.01\n",
    "\n",
    "encoder = cnn_encoder(n_hidden,data_dim,latent_dim,model_drop_rate)\n",
    "decoder = cnn_decoder(n_hidden,latent_dim,data_dim,model_drop_rate)\n",
    "enc_opt = t.optim.Adam(encoder.parameters(), lr = 1e-4)\n",
    "dec_opt = t.optim.Adam(decoder.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (25) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-491-4385fa1112fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_svgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-487-f535d01a7839>\u001b[0m in \u001b[0;36mtrain_svgd\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_for_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mlogpxz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_parts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mlogpxz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-459-94e5ad824a27>\u001b[0m in \u001b[0;36mbce_loss\u001b[1;34m(x_real, x_rec)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_rec\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-15\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx_real\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx_rec\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (25) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "train_svgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.no_grad():\n",
    "    data,target = next(iter(train_loader))\n",
    "    img = dropout(data[0].repeat(n_parts,1,1,1), input_drop_rate).view(n_parts, 1, 784)\n",
    "    z = encoder(img)\n",
    "    x_rec = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16fbabfe320>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16fbaff1400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16fbae2e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_rec[0].view(28,28))\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(img[0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            \n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with t.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN()\n",
    "optimizer = t.optim.Adam(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T480\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "C:\\Users\\T480\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3105, Accuracy: 911/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305918\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.618024\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.343367\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.191721\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.304363\n",
      "\n",
      "Test set: Avg. loss: 0.1880, Accuracy: 9399/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.153737\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.209451\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.113225\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.134839\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.188308\n",
      "\n",
      "Test set: Avg. loss: 0.1383, Accuracy: 9572/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.088676\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.178610\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.047906\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.153846\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.130385\n",
      "\n",
      "Test set: Avg. loss: 0.1340, Accuracy: 9597/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.140555\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.084165\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.126813\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.123869\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.140052\n",
      "\n",
      "Test set: Avg. loss: 0.1099, Accuracy: 9647/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.065564\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.103467\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.160947\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.146229\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.122996\n",
      "\n",
      "Test set: Avg. loss: 0.0972, Accuracy: 9700/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "test()\n",
    "for epoch in range(1,n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
